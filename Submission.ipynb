{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pandas==1.1.1 joblib==0.14.0 scikit-learn==0.22.1 smote-variants==0.3.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import math\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor,AdaBoostClassifier \n",
    "from sklearn.metrics import mean_squared_error,f1_score\n",
    "import smote_variants as sv\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## READING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_dir_train = 'challenge_data\\\\train\\\\'\n",
    "json_dir_test = 'challenge_data\\\\test\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents_train = []\n",
    "contents_test = []\n",
    "\n",
    "json_pattern_train = os.path.join(json_dir_train, '*.json')\n",
    "file_list = glob.glob(json_pattern_train)\n",
    "for file in file_list:\n",
    "    with open(file,'r') as f:\n",
    "        temp = json.load(f)\n",
    "    contents_train.extend(temp)\n",
    "\n",
    "json_pattern_test = os.path.join(json_dir_test, '*.json')\n",
    "file_list = glob.glob(json_pattern_test)\n",
    "for file in file_list:\n",
    "    with open(file,'r') as f:\n",
    "        temp = json.load(f)\n",
    "    contents_test.extend(temp)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame.from_dict(contents_train)\n",
    "df_test = pd.DataFrame.from_dict(contents_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape,df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a distinct list of technologies mentioned from which a seperate column for a tag is created.\n",
    "# observed that a certain technology like html, python has more no of challeneges and submission.\n",
    "def technology_transformation(data,mastertech_list = [\"Unknown\"]):\n",
    "    df = data.copy()\n",
    "    \n",
    "    def unique_ele(x):\n",
    "        for tech in x:\n",
    "            if tech not in mastertech_list:\n",
    "                mastertech_list.append(tech)\n",
    "        return x\n",
    "\n",
    "    df['tags'] = df['tags'].apply(lambda x : unique_ele(x))\n",
    "    return df,mastertech_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df,mastertech_list):\n",
    "    \n",
    "    # considering only common features across both active and completed challenges.\n",
    "    # This make sure that the code will work on both active and completed.\n",
    "    df = df[['track', 'legacy', 'phases', 'startDate','endDate', 'prizeSets', 'tags','winners']].copy()\n",
    "    \n",
    "    df['no_of_tags'] = df['tags'].apply(lambda x:len(x)) # calculating the no of tags as a feature\n",
    "    df['subTrack'] = df['legacy'].apply(lambda x: x['subTrack']) # calculating the subTrack as a feature\n",
    "    df['no_of_phases'] = df['phases'].apply(lambda x: len(x)) # calculating the no of phases as a feature\n",
    "    df['total_prize'] = df['prizeSets'].apply(lambda x: sum([i['value'] for i in x[0]['prizes']])) # calculating the total prize as a feature\n",
    "    df['no_of_winners'] = df['winners'].apply(lambda x: len(x)) # caculating the taget feature - no of winners\n",
    "    \n",
    "    # formatting the startDate and endDate of a challenge\n",
    "    for col in ['startDate','endDate']:\n",
    "        df['%s'%col] = pd.to_datetime(df['%s'%col],format='%Y-%m-%d')\n",
    "    for col in ['startDate','endDate']:\n",
    "        df['%s'%col] = df['%s'%col].dt.date\n",
    "    for col in ['startDate','endDate']:\n",
    "        df['%s'%col] = pd.to_datetime(df['%s'%col],format='%Y-%m-%d')  \n",
    "    \n",
    "    # calculating the no of days or the challenege duration\n",
    "    df['challenge_duration'] = abs(df['endDate'] -  df['startDate']).dt.days\n",
    "    \n",
    "    \n",
    "    ## handling technology list\n",
    "    for tech in mastertech_list:\n",
    "        df[tech] = 0\n",
    "\n",
    "    def find_tech(row):\n",
    "        for tech in row[\"tags\"]:\n",
    "            if tech in mastertech_list:\n",
    "                row[tech]=1\n",
    "            else:\n",
    "                row[\"Unknown\"]=1\n",
    "        return row\n",
    "\n",
    "    df= df.apply(lambda row : find_tech(row), axis = 1) \n",
    "\n",
    "    del df['tags']\n",
    "    \n",
    "    df['startDate'] = pd.to_datetime(df['startDate']).dt.date\n",
    "    df['endDate'] = pd.to_datetime(df['endDate']).dt.date\n",
    "\n",
    "\n",
    "    df['startDate'] = pd.to_datetime(df['startDate'])\n",
    "    df['endDate'] = pd.to_datetime(df['endDate'])\n",
    "    \n",
    "\n",
    "    ## Only considering the date values to remove or filter unwanted date values\n",
    "    df['start_day'] = df['startDate'].dt.day_name()\n",
    "    df['end_day'] = df['endDate'].dt.day_name()\n",
    "\n",
    "    day_dic ={\n",
    "        \"Sunday\":0,\n",
    "        \"Monday\":1,\n",
    "        \"Tuesday\":2,\n",
    "        \"Wednesday\":3,\n",
    "        \"Thursday\":4,\n",
    "        \"Friday\":5,\n",
    "        \"Saturday\":6\n",
    "    }\n",
    "    # calculating the day of teh start and end date\n",
    "    def convert_day(day):\n",
    "        return day_dic[day]\n",
    "\n",
    "    df['start_day'] = df['start_day'].apply(lambda x:convert_day(x))\n",
    "    df['end_day'] = df['end_day'].apply(lambda x:convert_day(x))\n",
    "\n",
    "    df.drop(['winners','phases','legacy','startDate','endDate','prizeSets'],axis=1,inplace=True)\n",
    "    \n",
    "    # one hot encoding of categorical features\n",
    "    df = pd.get_dummies(df,drop_first=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dictinct technology list\n",
    "df_train,mastertech_list = technology_transformation(df_train)\n",
    "df_test,mastertech_list = technology_transformation(df_test,mastertech_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess data\n",
    "df_train = preprocessing(df_train,mastertech_list)\n",
    "df_test = preprocessing(df_test,mastertech_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape,df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REGRESSION TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get X and y values for training and test set for a regression model\n",
    "X_train = df_train.drop(['no_of_winners'],axis=1).values\n",
    "y_train = df_train['no_of_winners'].values\n",
    "X_test = df_test.drop(['no_of_winners'],axis=1).values\n",
    "y_test = df_test['no_of_winners'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardization and normalization of the data\n",
    "sc = StandardScaler()\n",
    "n = MinMaxScaler()\n",
    "\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "X_train = n.fit_transform(X_train)\n",
    "X_test = n.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "GBR = GradientBoostingRegressor(learning_rate=0.4,max_depth=4,max_features = 'auto',min_samples_leaf =8,min_samples_split=5,n_estimators=62)\n",
    "GBR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLASSIFICATION TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the target variable for the classification model\n",
    "df_train[\"no_of_winners\"] = df_train[\"no_of_winners\"].apply(lambda x : 1 if x >= 1 else 0)\n",
    "df_test[\"no_of_winners\"] = df_test[\"no_of_winners\"].apply(lambda x : 1 if x >= 1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get X and y values for training and test set for a classification model\n",
    "X_train_class = df_train.drop(['no_of_winners'],axis=1).values\n",
    "y_train_class = df_train['no_of_winners'].values\n",
    "X_test_class = df_test.drop(['no_of_winners'],axis=1).values\n",
    "y_test_class = df_test['no_of_winners'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Target Distribution before Sampling - \")\n",
    "print(\"Train Target Distribution :\",Counter(y_train_class))\n",
    "print(\"Test Target Distribution :\",Counter(y_test_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a balanced dataset from the imbalanced dataset using oversampling\n",
    "oversampler= sv.polynom_fit_SMOTE(proportion= 1.5, topology= 'mesh', random_state=40)\n",
    "X_train_class, y_train_class= oversampler.sample(X_train_class, y_train_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardization  of the data\n",
    "sc_class = StandardScaler()\n",
    "X_train_class = sc_class.fit_transform(X_train_class)\n",
    "X_test_class = sc_class.transform(X_test_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Target Distribution after Sampling - \")\n",
    "print(\"Train Target Distribution :\",Counter(y_train_class))\n",
    "print(\"Test Target Distribution :\",Counter(y_test_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "ADA =  AdaBoostClassifier(algorithm='SAMME.R',\n",
    "                         base_estimator=None,\n",
    "                         learning_rate=0.2,\n",
    "                         n_estimators=500,\n",
    "                         random_state=None)\n",
    "\n",
    "ADA.fit(X_train_class,y_train_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVE MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(GBR, 'regression_model.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(ADA, 'classification_model.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred  = GBR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class = ADA.predict(X_test_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE = math.sqrt(mean_squared_error(y_test, y_pred))\n",
    "F1 = f1_score(y_test_class, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RMSE :\",RMSE)\n",
    "print(\"F1 :\",F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"FINAL METRIC SCORE : \",F1/(1+RMSE))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
